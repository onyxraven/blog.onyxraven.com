<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby | OnyxRaven]]></title>
  <link href="http://onyxraven.github.io/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://onyxraven.github.io/"/>
  <updated>2014-01-13T19:25:54-07:00</updated>
  <id>http://onyxraven.github.io/</id>
  <author>
    <name><![CDATA[Justin Hart]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Rails REST API versioning]]></title>
    <link href="http://onyxraven.github.io/blog/2013/09/18/rails-rest-api-versioning/"/>
    <updated>2013-09-18T09:39:00-06:00</updated>
    <id>http://onyxraven.github.io/blog/2013/09/18/rails-rest-api-versioning</id>
    <content type="html"><![CDATA[<p>There have been a few other articles regarding versioning REST APIs in Rails.  Many reference <a href="http://railscasts.com/episodes/350-rest-api-versioning">this RailsCasts (#350)</a> to set up header based versioning, and there have been a few setting up path based versioning using the &lsquo;namespace&rsquo; feature in Rails 3 routing.</p>

<p>Our API was set up with path based using routing namespaces, and we moved ahead happily with v1.</p>

<p>```ruby
namespace :v1 do
  resource :ping
end</p>

<p>class Api::V1::PingController &hellip;
end
<code>
</code>
GET <a href="http://example.org/v1/ping">http://example.org/v1/ping</a>
```</p>

<p>Recently we started working on v2 features, and started in a new namespace, looking just like v1.  To make it easy on our apps, we wanted to make all the API calls against the v2 api, even on controllers that didn&rsquo;t get an &lsquo;upgrade&rsquo; into the v2 namespace.</p>

<p><code>
http://example.org/v1/ping
http://example.org/v2/ping #fallback to the v1
http://example.org/v2/pong #use v2 namespace
</code></p>

<p>This is a non-obvious operation.  In most REST cases, redirects like explained in <a href="http://stackoverflow.com/questions/9627546/api-versioning-for-rails-routes/9627796#9627796">this StackOverflow post</a> are not possible because you shouldn&rsquo;t redirect POSTs (technically an HTTP 301 response should work, but there are few HTTP clients that respect that strict mode.  If you don&rsquo;t believe a 301 response to a POST should result in a new POST, read <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">the spec</a> carefully).</p>

<p><a href="http://joshsymonds.com/">Josh Symonds</a> talks about how <a href="http://joshsymonds.com/blog/2013/02/22/existing-rails-api-solutions-suck/">existing API solutions are terrible</a>, and really only one of the gems Symonds talks about in his post handles &lsquo;fallback&rsquo; apis: <a href="https://github.com/filtersquad/rocket_pants">rocket_pants</a>.  I wasn&rsquo;t keen on using the whole kit of rocket_pants features, so I looked into <a href="https://github.com/filtersquad/rocket_pants/blob/master/lib/rocket_pants/routing.rb">how the &lsquo;api&rsquo; method works</a>.  Its just a fancy wrapper around a &lsquo;scope&rsquo; line.</p>

<p>Taking a cue from that, I came up with the replacement for the &lsquo;namespace&rsquo; lines:</p>

<p>```ruby
scope :module => &lsquo;v2&rsquo;, :path => &lsquo;:api_version&rsquo;, :constraints => { :api_version => /v2/ } do
   resource :pong
end</p>

<p>scope :module => &lsquo;v1&rsquo;, :path => &lsquo;:api_version&rsquo;, :constraints => { :api_version => /v[12]/ } do
  resource :ping
end
```</p>

<p>A few notes about the scope line:</p>

<ul>
<li>specs/tests that test &lsquo;route_to&rsquo; assertions will need to respect the fact that :api_version will be included in the list of route parameters</li>
<li>regex against paths cannot be anchored.  It throws an exception at app startup time (which Passenger may hide), because those regexes are already anchored, and really you&rsquo;re only working on one piece of the path at a time.</li>
<li>Order matters in routing &ndash; it is evaluated top-down so pay attention to the fallbacks.</li>
</ul>


<p>Now, in the v2 scope, we can also override a given resource with a controller from the new namespace, since it will match first.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Local/Server synchronization with Ruby and FSEvent]]></title>
    <link href="http://onyxraven.github.io/blog/2011/10/02/sync-ruby-fsevent/"/>
    <updated>2011-10-02T03:12:00-06:00</updated>
    <id>http://onyxraven.github.io/blog/2011/10/02/sync-ruby-fsevent</id>
    <content type="html"><![CDATA[<p>A lot of the work I do is PHP/html type coding. I try to keep a local setup that is able to run all of my code without too much trouble, but eventually all that code has to be tested on something resembling the production environment, or there are certain functions that can only be performed there (say, handling NFS mounts, or attaching to databases otherwise firewalled on my local machine). In those situations, I need to be able to quickly copy my code from my local machine to the development server. I used to do this manually, but the cycle of edit-save-copy-test was really annoying. Aptana and Eclipse have some tools that help, but I don&rsquo;t use those tools anymore day-to-day, and they seemed to always get messed up.</p>

<p>I took while to find a suitable setup for keeping files in sync like this. Somehow I came across doubledown, a ruby script using the OSX FSEvent framework. For whatever reason, I couldn&rsquo;t quite make it work on my machine (YMMV), so I took the idea and searched for other uses of FSEvent out there. I came across a few rubygems wrapping FSEvent nicely, and wrote a script around that. First, you&rsquo;ll probably want to set up ssh keys. This will let you rsync over ssh without having to log in every time (kind of important on this one). I don&rsquo;t like the idea of having keys that don&rsquo;t have a password, so I use keychain to manage my keys. In my ~/.zshrc I have the following snippet:</p>

<p><div><script src='https://gist.github.com/4366205.js'></script>
<noscript><pre><code>w=`echo &quot;($RANDOM % 499) * 100000000000000000&quot; | bc -lws`; sleep $w
keychain --attempts 3 --lockwait 60 -q $HOME/.ssh/github_rsa $HOME/.ssh/onyx_dsa
if [ -f $HOME/.keychain/$HOST-sh ]; then
    source $HOME/.keychain/$HOST-sh
else
    echo &quot;No keychain for $HOST&quot;;
fi
</code></pre></noscript></div>
</p>

<p>The random delay lets me launch more than one shell at a time (my default windowgroup in Terminal.app is has two) without conflict.</p>

<p>Second, you&rsquo;ll want to have a way to fully-sync your directories. The following script does this with a single command, and with some options provided by gnu getopt. The biggest features are a preset source/destination (which can be appended), and skipping .svn/.hg directories. In a rush, skipping those makes a HUGE speed difference (especially when skipping svn).</p>

<p><div><script src='https://gist.github.com/4366220.js'></script>
<noscript><pre><code>#!/bin/bash
#requires gnu getopt
#requires rsync

GETOPT=&quot;/opt/local/bin/getopt&quot;
rsynccmd=&quot;rtlzv --exclude=compile --exclude=cache&quot;

localdir='/Volumes/Work/dev'
devdir='/home/username/dev'
devhost=&quot;dev&quot;

fromdev=0
nodelete=0
upfirst=0
withcustom=0
withsvn=0

tmp=`$GETOPT -o h?nRrs -l reverse,no-delete,help,dry-run:: -n $0 -- &quot;$@&quot;`

if [ $? != 0 ] ; then 
    echo $USAGE &gt;&amp;2 
    exit 1 
fi 

eval set -- &quot;$tmp&quot; 

# parse options 
while true; do  
    case $1 in
        -n|--dry-run )
            rsynccmd=&quot;n$rsynccmd&quot;
            shift;;
        --with-custom )
            withcustom=1
            shift;;
        --no-delete )
            nodelete=1
            shift;;
        -o|--config_override )
            override=1
            shift;;
        -R|-r|--reverse )
            fromdev=1
            shift;;
        -s|--svn )
            withsvn=1
            shift;;
        -- ) 
            shift
            break;; 
        * ) 
            echo $USAGE 
            exit 1;;
    esac
done

if [ $nodelete -eq 0 ]; then
    rsynccmd=&quot;$rsynccmd --delete&quot;
fi

if [ $withcustom -eq 0 ]; then
    rsynccmd=&quot;$rsynccmd --exclude=custom.ini&quot;
fi

if [ $withsvn -eq 0 ]; then
    rsynccmd=&quot;$rsynccmd --exclude=.svn&quot;
fi

if [ &quot;x$1&quot; == &quot;x&quot; ]; then
    if [ $fromdev -eq 0 ]; then
        echo rsync -$rsynccmd $localdir/ $devhost:$devdir/
        rsync -$rsynccmd $localdir/ $devhost:$devdir/
    else 
        echo rsync -$rsynccmd $devhost:$devdir/ $localdir/
        rsync -$rsynccmd $devhost:$devdir/ $localdir/
    fi
fi


while [ &quot;x$1&quot; != &quot;x&quot; ]; do
    dir=`echo $1 | tr '^' '/'`
    if [ $fromdev -eq 0 ]; then
         echo rsync -$rsynccmd $localdir/$dir/ $devhost:$devdir/$dir/
         rsync -$rsynccmd $localdir/$dir/ $devhost:$devdir/$dir/
    else
        echo rsync -$rsynccmd $devhost:$devdir/$dir/ $localdir/$dir/
        rsync -$rsynccmd $devhost:$devdir/$dir/ $localdir/$dir/
    fi

    shift
done</code></pre></noscript></div>
</p>

<p>Now for the actual ruby script using FSEvent. It also includes using growl to notify on synchronization events. While not required, it is nice to know when things are synched (and it lets me know the script is still running), but it can get a bit spammy (especially running svn up on a directory).</p>

<p><div><script src='https://gist.github.com/4366239.js'></script>
<noscript><pre><code>#!/usr/bin/env ruby
#requires osx fsevent
#requires growl with network registration enabled (at least once)
#requires the below rubygems
#requires rsync

require 'rubygems'
require 'rb-fsevent'
require 'ruby-growl'

local='/Volumes/Work/dev/'
remote='dev:/home/username/dev/'

# Decide on the local path.
Dir.mkdir(local) unless File.directory?(local)
local = File.expand_path(local)

# Parse the server and remote path.  Decide on the remote username.
raise unless remote =~ /^(?:([^@]+)@)?([^:]+):(.+)$/
    user, server, remote = $1, $2, $3
user ||= ENV[&quot;USER&quot;]

g = Growl.new(&quot;localhost&quot;, &quot;dirsync-monitor&quot;, [&quot;dirsync-monitor Push&quot;])
g.notify(&quot;dirsync-monitor Push&quot;, &quot;Watch Started&quot;, &quot;#{local} =&gt; #{remote}&quot;)

fsevent = FSEvent.new
fsevent.watch local do |directories|
    #$stderr.puts &quot;# detected change inside: #{directories.inspect}&quot;
    directories.each do |dir|
        pathname2 = &quot;#{dir.sub(local, &quot;&quot;)}&quot;
        #ignore some stuff
        if pathname2.match('/\.svn/.*$') != nil || 
            pathname2.match('/\.hg/.*$') != nil || 
            pathname2.match('/compile/$') != nil || 
            pathname2.match('/cache/$') != nil then
            next
        end
        l = &quot;#{local}#{pathname2}&quot;.gsub(' ', '\\\\ ')
        r =  &quot;#{user}@#{server}:#{remote}#{pathname2}&quot;.gsub(' ', '\\\\ ')

        cmd = &quot;rsync -tzplr --delete-after --exclude='/*/*' --exclude='custom.ini' --exclude='.svn' --exclude='.hg' --exclude='compile' --exclude='cache' --exclude='*.swp' #{l} #{r}&quot;
        #$stderr.puts cmd
        g.notify(&quot;dirsync-monitor Push&quot;, &quot;Sync&quot;, &quot;#{l} =&gt; #{r}&quot;)
        system(cmd)
    end
end
fsevent.run</code></pre></noscript></div>
</p>

<p>These scripts aren&rsquo;t perfect, and are meant to be modified to your own needs and preferences. Its so nice not to have to worry about manually syncing the directories anymore though!</p>
]]></content>
  </entry>
  
</feed>
